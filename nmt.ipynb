{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python自带\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 科学计算\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP 相关\n",
    "import jieba\n",
    "import torchtext\n",
    "from nltk import word_tokenize\n",
    "from nltk.translate import bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = torchtext.data.Field(tokenize=word_tokenize, eos_token='<eos>')\n",
    "TRG = torchtext.data.Field(tokenize=word_tokenize_zh, init_token='<sos>', eos_token='<eos>')\n",
    "\n",
    "train_data = torchtext.datasets.TranslationDataset(\n",
    "    path='data/NEU_',\n",
    "    exts=('en.txt', 'cn.txt'),\n",
    "    fields=(SRC, TRG)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227383\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = torchtext.datasets.TranslationDataset(\n",
    "    path='data/newsdev2017-enzh',\n",
    "    exts=('.en', '.zh'),\n",
    "    fields=(SRC, TRG)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2002\n"
     ]
    }
   ],
   "source": [
    "print(len(dev_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = torchtext.datasets.TranslationDataset(\n",
    "    path='data/newstest2017-enzh',\n",
    "    exts=('.en', '.zh'),\n",
    "    fields=(SRC, TRG)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001\n"
     ]
    }
   ],
   "source": [
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC.build_vocab(train_data.src, dev_data.src, test_data.src, min_freq=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRG.build_vocab(train_data.trg, dev_data.trg, test_data.trg, min_freq=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95167\n",
      "91404\n"
     ]
    }
   ],
   "source": [
    "print(len(SRC.vocab.__dict__['freqs']))\n",
    "print(len(TRG.vocab.__dict__['freqs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC.vocab.load_vectors(torchtext.vocab.Vectors('data/glove.840B.300d.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRG.vocab.load_vectors(torchtext.vocab.Vectors('data/sgns.target.word-word.dynwin5.thr10.neg5.dim300.iter5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    '''Encoder(bi-GRU)\n",
    "    '''\n",
    "    def __init__(self, pretrained_embed, padding_idx, fix, hidden_size,\n",
    "                 n_layers=1, dropout=0.5):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding.from_pretrained(pretrained_embed)\n",
    "        self.embedding.padding_idx = padding_idx\n",
    "        if fix:\n",
    "            self.embedding.weight.requires_grad = False\n",
    "        \n",
    "        self.gru = nn.GRU(self.embedding.embedding_dim, hidden_size, n_layers,\n",
    "                            dropout=dropout, bidirectional=True)\n",
    "\n",
    "    def forward(self, src, hidden=None):\n",
    "        '''\n",
    "        Inputs:\n",
    "            src: input word index\n",
    "            hidden: h_t-1 (num_layers * num_directions, batch, hidden_size)\n",
    "        Outputs:\n",
    "            output: [T*B*H]\n",
    "            hidden: h_t\n",
    "        '''\n",
    "        embeded = self.embedding(src)\n",
    "        outputs, hidden = self.gru(embeded, hidden)\n",
    "        \n",
    "        # Sum bi-lstm outputs\n",
    "        output = (outputs[:, :, :self.hidden_size] + \n",
    "                   outputs[:, :, self.hidden_size:])\n",
    "        return output, hidden\n",
    "\n",
    "\n",
    "class ConcatAttn(nn.Module):\n",
    "    '''Attention(concat)\n",
    "    Params:\n",
    "        hidden_size: hidden size\n",
    "    '''\n",
    "    def __init__(self, hidden_size):\n",
    "        super(ConcatAttn, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attn = nn.Linear(2 * hidden_size, hidden_size)\n",
    "        self.v = nn.Parameter(torch.rand(hidden_size))\n",
    "        stdv = 1.0 / sqrt(self.v.size(0))\n",
    "        self.v.data.uniform_(-stdv, stdv)\n",
    "    \n",
    "    def forward(self, hidden, encoder_output):\n",
    "        '''\n",
    "        Inputs:\n",
    "            hidden: [1*B*H] \n",
    "            encoder_output: [T*B*H]\n",
    "        Outputs:\n",
    "            energy: normalised weights [B*1*T]\n",
    "        '''\n",
    "        # Expand hidden [1*B*H] -> [T*B*H] -> [B*T*H]\n",
    "        hidden = hidden.repeat(encoder_output.size(0), 1, 1).transpose(0, 1)\n",
    "\n",
    "        # Transfer encoder_output to [B*T*H]\n",
    "        encoder_output = encoder_output.transpose(0, 1)\n",
    "\n",
    "        # Calculate energy and normalise  [B*1*T]\n",
    "        attn_energy = self.score(hidden, encoder_output)\n",
    "        return F.softmax(attn_energy, dim=2)\n",
    "\n",
    "    def score(self, hidden, encoder_output):\n",
    "        '''\n",
    "        Inputs:\n",
    "            hidden: [B*T*H]\n",
    "            encoder_output: [B*T*H]\n",
    "        Outputs:\n",
    "            attn_energy: weights [B*T]\n",
    "        '''\n",
    "        # Project vectors [B*T*2H] -> [B*T*H] -> [B*H*T]\n",
    "        energy = self.attn(torch.cat([hidden, encoder_output], 2))\n",
    "        energy = energy.transpose(1, 2)\n",
    "        \n",
    "        # Expend v  [H] -> [B*H] -> [B*1*H]\n",
    "        v = self.v.repeat(encoder_output.size(0), 1).unsqueeze(1)\n",
    "        \n",
    "        # [B*1*H] * [B*H*T] -> [B*1*T]\n",
    "        attn_energy = torch.bmm(v, energy)\n",
    "        return attn_energy\n",
    "\n",
    "        \n",
    "class BilinearAttn(nn.Module):\n",
    "    '''Attention(bilinear)\n",
    "    Params:\n",
    "        hidden_size: hidden size\n",
    "    '''\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BilinearAttn, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bilinear = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "    \n",
    "    def forward(self, hidden, encoder_output):\n",
    "        '''\n",
    "        Inputs:\n",
    "            hidden: [1*B*H] \n",
    "            encoder_output: [T*B*H]\n",
    "        Outputs:\n",
    "            energy: normalised weights [B*1*T]\n",
    "        '''\n",
    "        # [T*B*H] -> [T*B*H] -> [B*H*T]\n",
    "        wh = self.bilinear(encoder_output).permute(1, 2, 0)\n",
    "        \n",
    "        # [1*B*H] -> [B*1*H] x [B*H*T] => [B*1*T]\n",
    "        score = hidden.transpose(0, 1).bmm(wh)\n",
    "        \n",
    "        return F.softmax(score, dim=2)\n",
    "    \n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    '''Decoder(bi-GRU)\n",
    "    '''\n",
    "    def __init__(self, pretrained_embed, padding_idx, hidden_size, fix, output_size,\n",
    "                 n_layers=1, dropout=0.2):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding.from_pretrained(pretrained_embed)\n",
    "        self.embedding.padding_idx = padding_idx\n",
    "        if fix:\n",
    "            self.embedding.weight.requires_grad = False\n",
    "            \n",
    "        self.dropout = nn.Dropout(dropout, inplace=True)\n",
    "        \n",
    "        self.attention = BilinearAttn(hidden_size)\n",
    "        \n",
    "        self.gru = nn.GRU(\n",
    "            self.embedding.embedding_dim,\n",
    "            hidden_size,\n",
    "            n_layers,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        self.linear1 = nn.Linear(hidden_size * 2, hidden_size * 2, bias=False)\n",
    "        self.linear2 = nn.Linear(hidden_size * 2, output_size, bias=False)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_output):\n",
    "        '''\n",
    "        Inputs:\n",
    "            input: [B]\n",
    "            hidden: [layers*B*H]\n",
    "            encoder_output: [T*B*H]\n",
    "        Outputs:\n",
    "            p: [B*O]\n",
    "            hidden: [layers*B*H]\n",
    "        '''\n",
    "        # [B] -> [B*E] -> [1*B*E]\n",
    "        embeded = self.embedding(input).unsqueeze(0) \n",
    "            \n",
    "        # [1*B*H], [layers*B*H]\n",
    "        output, hidden = self.gru(embeded, hidden)\n",
    "        \n",
    "        # ht: [B*H]  the last layer\n",
    "        ht = hidden[-1, :, :]\n",
    "        \n",
    "        # [1*B*T] and [T*B*H] -> [B*1*T]\n",
    "        attn_weights = self.attention(ht.unsqueeze(0), encoder_output)\n",
    "        \n",
    "        # [B*1*T] x [B*T*H] => [B*1*H] -> [B*H]\n",
    "        c = attn_weights.bmm(encoder_output.transpose(0, 1)).squeeze(1)\n",
    "        \n",
    "        # concat c and h => [B*2H] => [B*H] \n",
    "        attn_vector = torch.tanh(self.linear1(\n",
    "            torch.cat([c, ht], dim=1)\n",
    "        ))\n",
    "        \n",
    "        # [B*H] -> [B*O]\n",
    "        p = F.log_softmax(self.linear2(attn_vector), dim=1)\n",
    "\n",
    "        return p, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = torchtext.data.BucketIterator(\n",
    "    dataset=train_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "dev_iter = torchtext.data.BucketIterator(\n",
    "    dataset=dev_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_iter = torchtext.data.BucketIterator(\n",
    "    dataset=test_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "EOS_TOKEN = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(epoch, encoder, decoder, encoder_optimizer, decoder_optimizer ,criterion, eval_steps, train_iter, dev_iter, device):\n",
    "\n",
    "    writer = SummaryWriter()\n",
    "    encoder.to(device)\n",
    "    decoder.to(device)\n",
    "    \n",
    "    step = 0\n",
    "    train_loss = 0.0\n",
    "    lowest_loss = 1e5\n",
    "    \n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    for e in range(epoch):\n",
    "        train_iter.init_epoch()\n",
    "        for train_batch in iter(train_iter):\n",
    "            step += 1\n",
    "            \n",
    "            # [T*B]\n",
    "            src = train_batch.src.to(device)\n",
    "            trg = train_batch.trg.to(device)\n",
    "            \n",
    "            encoder_optimizer.zero_grad()\n",
    "            decoder_optimizer.zero_grad()\n",
    "            \n",
    "            # encoder\n",
    "            encoder_output, hidden = encoder(src)\n",
    "            \n",
    "            # decoder            \n",
    "            hidden = hidden[:decoder.n_layers]\n",
    "            decoder_input = trg[0] # SOS\n",
    "            \n",
    "            loss = 0.0\n",
    "            for i in range(trg.size(0) - 1):\n",
    "                p, hidden = decoder(\n",
    "                    decoder_input, hidden, encoder_output\n",
    "                )\n",
    "                loss += criterion(p, trg[i+1])\n",
    "                decoder_input = trg[i+1]\n",
    "                \n",
    "            loss.backward()\n",
    "            train_loss += loss.item() / (trg.size(0) - 1)\n",
    "            clip_grad_norm_(encoder.parameters(), 0.5)\n",
    "            clip_grad_norm_(decoder.parameters(), 0.5)\n",
    "            encoder_optimizer.step()\n",
    "            decoder_optimizer.step()\n",
    "            \n",
    "            if (step % eval_steps) == 0:\n",
    "                with torch.no_grad():\n",
    "                    encoder.eval()\n",
    "                    decoder.eval()\n",
    "                    \n",
    "                    dev_iter.init_epoch()\n",
    "                    dev_loss = 0.0\n",
    "                    dev_step = 0\n",
    "                    for dev_batch in iter(dev_iter):\n",
    "                        dev_step += 1\n",
    "                        dev_src = dev_batch.src.to(device)\n",
    "                        dev_trg = dev_batch.trg.to(device)\n",
    "                        \n",
    "                        encoder_output, hidden = encoder(dev_src)\n",
    "                        hidden = hidden[:decoder.n_layers]\n",
    "                        decoder_input = dev_trg[0]\n",
    "                        loss = 0.0\n",
    "                        for i in range(dev_trg.size(0) - 1):\n",
    "                            p, hidden = decoder(\n",
    "                                decoder_input, hidden, encoder_output\n",
    "                            )\n",
    "                            loss += criterion(p, dev_trg[i+1])\n",
    "                            decoder_input = dev_trg[i+1] \n",
    "                        \n",
    "                        dev_loss += loss.item() / (dev_trg.size(0) - 1)\n",
    "                    \n",
    "                    train_loss /= eval_steps\n",
    "                    dev_loss /= dev_step\n",
    "                    print(\"epoch %d steps %d train_loss %.4f train_ppl %5.2f dev_loss %.4f dev_ppl %5.2f\" % (\n",
    "                        e, step, train_loss, np.exp(train_loss), dev_loss, np.exp(dev_loss)\n",
    "                    ))\n",
    "                    \n",
    "                    writer.add_scalar('train/loss', train_loss, step)\n",
    "                    writer.add_scalar('train/perplexity', np.exp(train_loss), step)\n",
    "                    writer.add_scalar('dev/loss', dev_loss, step)\n",
    "                    writer.add_scalar('dev/perplexity', np.exp(dev_loss), step)\n",
    "                    \n",
    "                    if dev_loss < lowest_loss:\n",
    "                        dev_loss = lowest_loss\n",
    "                        save(\n",
    "                            encoder=encoder,\n",
    "                            decoder=decoder,\n",
    "                            info={'steps':step, 'epoch':e, 'train_loss':train_loss, 'train_ppl':np.exp(train_loss), 'dev_loss':dev_loss, 'dev_ppl':np.exp(dev_loss)}\n",
    "                        )\n",
    "                    \n",
    "                    train_loss = 0.0\n",
    "                    encoder.train()\n",
    "                    decoder.train()\n",
    "\n",
    "def save(encoder, decoder, info):\n",
    "    torch.save(info, 'best_model.info')\n",
    "    torch.save(encoder, 'best_encoder.m')\n",
    "    torch.save(decoder, 'best_decoder.m')\n",
    "    \n",
    "def load():\n",
    "    encoder = torch.load('best_encoder.m')\n",
    "    decoder = torch.load('best_decoder.m')\n",
    "    info = torch.load('best_model.info')\n",
    "    return encoder, decoder, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is available\n"
     ]
    }
   ],
   "source": [
    "choise = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(choise + \" is available\")\n",
    "device = torch.device(choise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 steps 500 train_loss 3.3863 train_ppl 29.55 dev_loss 3.9917 dev_ppl 54.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zyc/.conda/envs/zyc/lib/python3.6/site-packages/torch/serialization.py:250: UserWarning: Couldn't retrieve source code for container of type Encoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/zyc/.conda/envs/zyc/lib/python3.6/site-packages/torch/serialization.py:250: UserWarning: Couldn't retrieve source code for container of type Decoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/zyc/.conda/envs/zyc/lib/python3.6/site-packages/torch/serialization.py:250: UserWarning: Couldn't retrieve source code for container of type BilinearAttn. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 steps 1000 train_loss 2.9894 train_ppl 19.87 dev_loss 3.8465 dev_ppl 46.83\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(pretrained_embed=SRC.vocab.vectors, padding_idx=SRC.vocab.stoi[SRC.pad_token], fix=True, hidden_size=128, dropout=0.3, n_layers=4)\n",
    "decoder = Decoder(pretrained_embed=TRG.vocab.vectors, padding_idx=TRG.vocab.stoi[TRG.pad_token], fix=True, hidden_size=128, dropout=0.3, n_layers=4, output_size=len(TRG.vocab.freqs))\n",
    "\n",
    "encoder_optimizer = optim.Adam(filter(lambda p: p.requires_grad, encoder.parameters()), lr=1e-3)\n",
    "decoder_optimizer = optim.Adam(filter(lambda p: p.requires_grad, decoder.parameters()), lr=1e-3)\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "\n",
    "training(epoch=20, encoder=encoder, decoder=decoder, encoder_optimizer=encoder_optimizer, decoder_optimizer=decoder_optimizer, \n",
    "         criterion=criterion, eval_steps=500, train_iter=train_iter, dev_iter=dev_iter, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:zyc]",
   "language": "python",
   "name": "conda-env-zyc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
