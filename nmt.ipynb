{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python自带\n",
    "import gc\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "from lxml import etree\n",
    "from queue import Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 科学计算\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP 相关\n",
    "import jieba\n",
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画图\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import seaborn as sns\n",
    "\n",
    "myfont=FontProperties(fname=r'/home/zyc/Downloads/SimHei.ttf',size=14)\n",
    "\n",
    "sns.set(font=myfont.get_name())\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(src):\n",
    "    return src.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = torchtext.data.Field(tokenize=tokenizer, eos_token='<eos>')\n",
    "TRG = torchtext.data.Field(tokenize=tokenizer, init_token='<sos>', eos_token='<eos>')\n",
    "\n",
    "dataset = torchtext.datasets.TranslationDataset(\n",
    "    path='data/NEU',\n",
    "    exts=('.en.tok.bpe', '.zh.tok'),\n",
    "    fields=(SRC, TRG)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, dev_data = dataset.split(split_ratio=0.98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data, test_data = dev_data.split(split_ratio=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1959416\n",
      "19994\n",
      "19994\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(test_data))\n",
    "print(len(dev_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC.build_vocab(train_data.src, dev_data.src, test_data.src, max_size=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRG.build_vocab(train_data.trg, dev_data.trg, test_data.trg, max_size=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32115\n",
      "50004\n"
     ]
    }
   ],
   "source": [
    "print(len(SRC.vocab.itos))\n",
    "print(len(TRG.vocab.itos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['souri',\n",
       " 'staur@@',\n",
       " 'susp@@',\n",
       " 'tellig@@',\n",
       " 'therto',\n",
       " 'thwest',\n",
       " 'tremend@@',\n",
       " 'ublic',\n",
       " 'usetts',\n",
       " 'warri@@']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SRC.vocab.itos[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC.vocab.load_vectors(torchtext.vocab.Vectors('data/glove.840B.300d.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRG.vocab.load_vectors(torchtext.vocab.Vectors('data/sgns.target.word-word.dynwin5.thr10.neg5.dim300.iter5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    '''Encoder(bi-GRU)\n",
    "    '''\n",
    "    def __init__(self, pretrained_embed, padding_idx, fix, hidden_size,\n",
    "                 n_layers=1, dropout=0.5):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding.from_pretrained(pretrained_embed)\n",
    "        self.embedding.padding_idx = padding_idx\n",
    "        if fix:\n",
    "            self.embedding.weight.requires_grad = False\n",
    "        \n",
    "        self.gru = nn.GRU(self.embedding.embedding_dim, hidden_size, n_layers,\n",
    "                            dropout=dropout, bidirectional=True)\n",
    "\n",
    "    def forward(self, src, hidden=None):\n",
    "        '''\n",
    "        Inputs:\n",
    "            src: input word index\n",
    "            hidden: h_t-1 (num_layers * num_directions, batch, hidden_size)\n",
    "        Outputs:\n",
    "            output: [T*B*H]\n",
    "            hidden: h_t\n",
    "        '''\n",
    "        embeded = self.embedding(src)\n",
    "        outputs, hidden = self.gru(embeded, hidden)\n",
    "        \n",
    "        # Sum bi-lstm outputs\n",
    "        output = (outputs[:, :, :self.hidden_size] + \n",
    "                   outputs[:, :, self.hidden_size:])\n",
    "    \n",
    "        return output, hidden\n",
    "\n",
    "\n",
    "class ConcatAttn(nn.Module):\n",
    "    '''Attention(concat)\n",
    "    Params:\n",
    "        hidden_size: hidden size\n",
    "    '''\n",
    "    def __init__(self, hidden_size):\n",
    "        super(ConcatAttn, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attn = nn.Linear(2 * hidden_size, hidden_size)\n",
    "        self.v = nn.Parameter(torch.rand(hidden_size))\n",
    "        stdv = 1.0 / sqrt(self.v.size(0))\n",
    "        self.v.data.uniform_(-stdv, stdv)\n",
    "    \n",
    "    def forward(self, hidden, encoder_output):\n",
    "        '''\n",
    "        Inputs:\n",
    "            hidden: [1*B*H] \n",
    "            encoder_output: [T*B*H]\n",
    "        Outputs:\n",
    "            energy: normalised weights [B*1*T]\n",
    "        '''\n",
    "        # Expand hidden [1*B*H] -> [T*B*H] -> [B*T*H]\n",
    "        hidden = hidden.repeat(encoder_output.size(0), 1, 1).transpose(0, 1)\n",
    "\n",
    "        # Transfer encoder_output to [B*T*H]\n",
    "        encoder_output = encoder_output.transpose(0, 1)\n",
    "\n",
    "        # Calculate energy and normalise  [B*1*T]\n",
    "        attn_energy = self.score(hidden, encoder_output)\n",
    "        return F.softmax(attn_energy, dim=2)\n",
    "\n",
    "    def score(self, hidden, encoder_output):\n",
    "        '''\n",
    "        Inputs:\n",
    "            hidden: [B*T*H]\n",
    "            encoder_output: [B*T*H]\n",
    "        Outputs:\n",
    "            attn_energy: weights [B*T]\n",
    "        '''\n",
    "        # Project vectors [B*T*2H] -> [B*T*H] -> [B*H*T]\n",
    "        energy = self.attn(torch.cat([hidden, encoder_output], 2))\n",
    "        energy = energy.transpose(1, 2)\n",
    "        \n",
    "        # Expend v  [H] -> [B*H] -> [B*1*H]\n",
    "        v = self.v.repeat(encoder_output.size(0), 1).unsqueeze(1)\n",
    "        \n",
    "        # [B*1*H] * [B*H*T] -> [B*1*T]\n",
    "        attn_energy = torch.bmm(v, energy)\n",
    "        return attn_energy\n",
    "\n",
    "        \n",
    "class BilinearAttn(nn.Module):\n",
    "    '''Attention(bilinear)\n",
    "    Params:\n",
    "        hidden_size: hidden size\n",
    "    '''\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BilinearAttn, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bilinear = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "    \n",
    "    def forward(self, hidden, encoder_output):\n",
    "        '''\n",
    "        Inputs:\n",
    "            hidden: [1*B*H] \n",
    "            encoder_output: [T*B*H]\n",
    "        Outputs:\n",
    "            energy: normalised weights [B*1*T]\n",
    "        '''\n",
    "        # [T*B*H] -> [T*B*H] -> [B*H*T]\n",
    "        wh = self.bilinear(encoder_output).permute(1, 2, 0)\n",
    "        \n",
    "        # [1*B*H] -> [B*1*H] x [B*H*T] => [B*1*T]\n",
    "        score = hidden.transpose(0, 1).bmm(wh)\n",
    "        \n",
    "        return F.softmax(score, dim=2)\n",
    "    \n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    '''Decoder(bi-GRU)\n",
    "    '''\n",
    "    def __init__(self, pretrained_embed, padding_idx, hidden_size, fix, output_size,\n",
    "                 n_layers=1, dropout=0.2):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding.from_pretrained(pretrained_embed)\n",
    "        self.embedding.padding_idx = padding_idx\n",
    "        if fix:\n",
    "            self.embedding.weight.requires_grad = False\n",
    "            \n",
    "        self.dropout = nn.Dropout(dropout, inplace=True)\n",
    "        \n",
    "        self.attention = BilinearAttn(hidden_size)\n",
    "        \n",
    "        self.gru = nn.GRU(\n",
    "            self.embedding.embedding_dim,\n",
    "            hidden_size,\n",
    "            n_layers,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        self.linear1 = nn.Linear(hidden_size * 2, hidden_size * 2, bias=False)\n",
    "        self.linear2 = nn.Linear(hidden_size * 2, output_size, bias=False)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_output):\n",
    "        '''\n",
    "        Inputs:\n",
    "            input: [B]\n",
    "            hidden: [layers*B*H]\n",
    "            encoder_output: [T*B*H]\n",
    "        Outputs:\n",
    "            p: [B*O]\n",
    "            hidden: [layers*B*H]\n",
    "        '''\n",
    "        # [B] -> [B*E] -> [1*B*E]\n",
    "        embeded = self.embedding(input).unsqueeze(0) \n",
    "            \n",
    "        # [1*B*H], [layers*B*H]\n",
    "        output, hidden = self.gru(embeded, hidden)\n",
    "        \n",
    "        # ht: [B*H]  the last layer\n",
    "        ht = hidden[-1, :, :]\n",
    "        \n",
    "        # [1*B*T] and [T*B*H] -> [B*1*T]\n",
    "        attn_weights = self.attention(ht.unsqueeze(0), encoder_output)\n",
    "        \n",
    "        # [B*1*T] x [B*T*H] => [B*1*H] -> [B*H]\n",
    "        c = attn_weights.bmm(encoder_output.transpose(0, 1)).squeeze(1)\n",
    "        \n",
    "        # concat c and h => [B*2H] => [B*H] \n",
    "        attn_vector = torch.tanh(self.linear1(\n",
    "            torch.cat([c, ht], dim=1)\n",
    "        ))\n",
    "        \n",
    "        # [B*H] -> [B*O]\n",
    "        p = F.log_softmax(self.linear2(attn_vector), dim=1)\n",
    "        \n",
    "        return p, hidden, attn_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = torchtext.data.BucketIterator(\n",
    "    dataset=train_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "dev_iter = torchtext.data.BucketIterator(\n",
    "    dataset=dev_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_iter = torchtext.data.BucketIterator(\n",
    "    dataset=test_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(epoch, encoder, decoder, encoder_optimizer, decoder_optimizer ,criterion, eval_steps, train_iter, dev_iter, device, writer, warmup):\n",
    "    encoder.to(device)\n",
    "    decoder.to(device)\n",
    "    \n",
    "    step = 0\n",
    "    train_loss = 0.0\n",
    "    lowest_loss = 1e5\n",
    "    \n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    for e in range(epoch):\n",
    "        if e == warmup:\n",
    "            encoder.embedding.weight.requires_grad = True\n",
    "            decoder.embedding.weight.requires_grad = True\n",
    "            encoder_optimizer = optim.Adam(filter(lambda p: p.requires_grad, encoder.parameters()), lr=1e-4)\n",
    "            decoder_optimizer = optim.Adam(filter(lambda p: p.requires_grad, decoder.parameters()), lr=1e-4)\n",
    "        \n",
    "        train_iter.init_epoch()\n",
    "        for train_batch in iter(train_iter):\n",
    "            step += 1\n",
    "            \n",
    "            # [T*B]\n",
    "            src = train_batch.src.to(device)\n",
    "            trg = train_batch.trg.to(device)\n",
    "            \n",
    "            encoder_optimizer.zero_grad()\n",
    "            decoder_optimizer.zero_grad()\n",
    "            \n",
    "            # encoder\n",
    "            encoder_output, hidden = encoder(src)\n",
    "            \n",
    "            # decoder            \n",
    "            hidden = hidden[:decoder.n_layers]\n",
    "            decoder_input = trg[0] # SOS\n",
    "            \n",
    "            loss = 0.0\n",
    "            for i in range(trg.size(0) - 1):\n",
    "                p, hidden, _ = decoder(\n",
    "                    decoder_input, hidden, encoder_output\n",
    "                )\n",
    "                loss += criterion(p, trg[i+1])\n",
    "                decoder_input = trg[i+1]\n",
    "                \n",
    "            loss.backward()\n",
    "            train_loss += loss.item() / (trg.size(0) - 1)\n",
    "            clip_grad_norm_(encoder.parameters(), 0.5)\n",
    "            clip_grad_norm_(decoder.parameters(), 0.5)\n",
    "            encoder_optimizer.step()\n",
    "            decoder_optimizer.step()\n",
    "            \n",
    "            if (step % eval_steps) == 0:\n",
    "                with torch.no_grad():\n",
    "                    encoder.eval()\n",
    "                    decoder.eval()\n",
    "                    \n",
    "                    dev_iter.init_epoch()\n",
    "                    dev_loss = 0.0\n",
    "                    dev_step = 0\n",
    "                    for dev_batch in iter(dev_iter):\n",
    "                        dev_step += 1\n",
    "                        dev_src = dev_batch.src.to(device)\n",
    "                        dev_trg = dev_batch.trg.to(device)\n",
    "                        \n",
    "                        encoder_output, hidden = encoder(dev_src)\n",
    "                        hidden = hidden[:decoder.n_layers]\n",
    "                        decoder_input = dev_trg[0]\n",
    "                        loss = 0.0\n",
    "                        for i in range(dev_trg.size(0) - 1):\n",
    "                            p, hidden, _ = decoder(\n",
    "                                decoder_input, hidden, encoder_output\n",
    "                            )\n",
    "                            loss += criterion(p, dev_trg[i+1])\n",
    "                            decoder_input = dev_trg[i+1] \n",
    "                        \n",
    "                        dev_loss += loss.item() / (dev_trg.size(0) - 1)\n",
    "                    \n",
    "                    train_loss /= eval_steps\n",
    "                    dev_loss /= dev_step\n",
    "                    print(\"epoch %d steps %d train_loss %.4f train_ppl %5.2f dev_loss %.4f dev_ppl %5.2f\" % (\n",
    "                        e, step, train_loss, np.exp(train_loss), dev_loss, np.exp(dev_loss)\n",
    "                    ))\n",
    "                    \n",
    "                    writer.add_scalar('train/loss', train_loss, step)\n",
    "                    writer.add_scalar('train/perplexity', np.exp(train_loss), step)\n",
    "                    writer.add_scalar('dev/loss', dev_loss, step)\n",
    "                    writer.add_scalar('dev/perplexity', np.exp(dev_loss), step)\n",
    "                    \n",
    "                    if dev_loss < lowest_loss:\n",
    "                        lowest_loss = dev_loss\n",
    "                        save(\n",
    "                            encoder=encoder,\n",
    "                            decoder=decoder,\n",
    "                            info={'steps':step, 'epoch':e, 'train_loss':train_loss, 'train_ppl':np.exp(train_loss), 'dev_loss':dev_loss, 'dev_ppl':np.exp(dev_loss)}\n",
    "                        )\n",
    "                    \n",
    "                    train_loss = 0.0\n",
    "                    encoder.train()\n",
    "                    decoder.train()\n",
    "\n",
    "def save(encoder, decoder, info):\n",
    "    torch.save(info, 'best_model.info')\n",
    "    torch.save(encoder.state_dict(), 'best_encoder.m')\n",
    "    torch.save(decoder.state_dict(), 'best_decoder.m')\n",
    "    \n",
    "def load():\n",
    "    encoder = Encoder(pretrained_embed=SRC.vocab.vectors, padding_idx=SRC.vocab.stoi[SRC.pad_token], fix=True, hidden_size=1000, dropout=0.3, n_layers=4)\n",
    "    decoder = Decoder(pretrained_embed=TRG.vocab.vectors, padding_idx=TRG.vocab.stoi[TRG.pad_token], fix=True, hidden_size=1000, dropout=0.3, n_layers=4, output_size=len(TRG.vocab.itos))\n",
    "    encoder.load_state_dict(torch.load('best_encoder.m'))\n",
    "    decoder.load_state_dict(torch.load('best_decoder.m'))\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    info = torch.load('best_model.info')\n",
    "    return encoder, decoder, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is available\n"
     ]
    }
   ],
   "source": [
    "choise = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(choise + \" is available\")\n",
    "device = torch.device(choise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 steps 1000 train_loss 3.5105 train_ppl 33.46 dev_loss 3.2044 dev_ppl 24.64\n",
      "epoch 0 steps 2000 train_loss 3.1038 train_ppl 22.28 dev_loss 2.9857 dev_ppl 19.80\n",
      "epoch 0 steps 3000 train_loss 2.9334 train_ppl 18.79 dev_loss 2.8602 dev_ppl 17.46\n",
      "epoch 0 steps 4000 train_loss 2.8476 train_ppl 17.25 dev_loss 2.7595 dev_ppl 15.79\n",
      "epoch 0 steps 5000 train_loss 2.7630 train_ppl 15.85 dev_loss 2.7153 dev_ppl 15.11\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(pretrained_embed=SRC.vocab.vectors, padding_idx=SRC.vocab.stoi[SRC.pad_token], fix=True, hidden_size=1000, dropout=0.3, n_layers=4)\n",
    "decoder = Decoder(pretrained_embed=TRG.vocab.vectors, padding_idx=TRG.vocab.stoi[TRG.pad_token], fix=True, hidden_size=1000, dropout=0.3, n_layers=4, output_size=len(TRG.vocab.itos))\n",
    "\n",
    "encoder_optimizer = optim.Adam(filter(lambda p: p.requires_grad, encoder.parameters()), lr=1e-4)\n",
    "decoder_optimizer = optim.Adam(filter(lambda p: p.requires_grad, decoder.parameters()), lr=1e-4)\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "writer = SummaryWriter()\n",
    "training(epoch=20, encoder=encoder, decoder=decoder, encoder_optimizer=encoder_optimizer, decoder_optimizer=decoder_optimizer, \n",
    "         criterion=criterion, eval_steps=1000, train_iter=train_iter, dev_iter=dev_iter, device=device, writer=writer, warmup=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'steps': 226000,\n",
       " 'epoch': 3,\n",
       " 'train_loss': 1.6976676134959283,\n",
       " 'train_ppl': 5.461194908347954,\n",
       " 'dev_loss': 1.700731337990908,\n",
       " 'dev_ppl': 5.477952161656701}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder, decoder, info = load()\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self, hidden, previous_node, decoder_input, attn, log_prob, length):\n",
    "        self.hidden = hidden\n",
    "        self.previous_node = previous_node\n",
    "        self.decoder_input = decoder_input\n",
    "        self.attn = attn\n",
    "        self.log_prob = log_prob\n",
    "        self.length = length        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search(src, beam_width=3):\n",
    "    words = tokenizer(src) \n",
    "    indices = [SRC.vocab.stoi[word] for word in words]\n",
    "    print(indices)\n",
    "    input_tensor = torch.LongTensor(indices).unsqueeze(1)\n",
    "    # [1*T]\n",
    "    encoder_output, hidden = encoder(input_tensor)\n",
    "    hidden = hidden[:decoder.n_layers]\n",
    "    decoder_input = torch.tensor(2).unsqueeze(0)\n",
    "    \n",
    "    node = Node(hidden, None, decoder_input, None, 0, 1)\n",
    "    q = Queue()\n",
    "    q.put(node)\n",
    "    \n",
    "    end_nodes = []\n",
    "    while not q.empty():\n",
    "        candidates = []\n",
    "        # level traversal\n",
    "        for _ in range(q.qsize()):\n",
    "            node = q.get()\n",
    "            decoder_input = node.decoder_input\n",
    "            hidden = node.hidden\n",
    "            \n",
    "            if decoder_input.item() == 3 or node.length >= 50:\n",
    "                end_nodes.append(node)\n",
    "                continue\n",
    "            \n",
    "            decoder.named_parameters\n",
    "            log_prob, hidden, attn = decoder(\n",
    "                decoder_input, hidden, encoder_output\n",
    "            )\n",
    "        \n",
    "            log_prob, indices = log_prob[0][1:].topk(beam_width)\n",
    "            indices += 1\n",
    "            \n",
    "            for k in range(beam_width):\n",
    "                index = indices[k].unsqueeze(0)\n",
    "                log_p = log_prob[k].item()\n",
    "                child = Node(hidden, node, index, attn, node.log_prob + log_p, node.length + 1)\n",
    "                candidates.append((node.log_prob + log_p, child))\n",
    "        \n",
    "        candidates = sorted(candidates, reverse=True)\n",
    "        length = min(len(candidates), beam_width)\n",
    "        for i in range(length):\n",
    "            q.put(candidates[i][1])  \n",
    "    \n",
    "    '''\n",
    "    for node in end_nodes:\n",
    "        res = []\n",
    "        value = node.log_prob\n",
    "        while node.previous_node != None:\n",
    "            res.append(TRG.vocab.itos[node.decoder_input.item()])\n",
    "            node = node.previous_node\n",
    "        print(''.join(res[::-1]), value)'''\n",
    "    node = end_nodes[0]\n",
    "    res = []\n",
    "    attns = []\n",
    "    while node.previous_node != None:\n",
    "        res.append(TRG.vocab.itos[node.decoder_input.item()])\n",
    "        attns.append(node.attn.squeeze(0).squeeze(0).numpy().tolist())\n",
    "        node = node.previous_node\n",
    "    print(' '.join(res[::-1][:-1]))\n",
    "    return attns[::-1][:-1], res[::-1][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(15,10)}) \n",
    "sns.set(font=myfont.get_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'trees', 'began', 'to', 'shoot', 'new', 'buds', 'and', 'leaves', '.']\n",
      "The trees began to shoot new buds and leaves .\n",
      "树苗开始抽出新的嫩芽,长出新的枝叶.\n",
      "[12, 1646, 885, 8, 5328, 68, 16503, 7, 1726, 3]\n",
      "树木 开始 长出 新 的 芽 和 树叶 。\n",
      "['树木', '开始', '长出', '新', '的', '芽', '和', '树叶', '。']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    index = 54\n",
    "    print(test_data[index].src)\n",
    "    print(' '.join(test_data[index].src))\n",
    "    print(''.join(test_data[index].trg))\n",
    "    src = ' '.join(test_data[index].src)\n",
    "    attns, x_labels = beam_search(src, 3)\n",
    "    print(x_labels)\n",
    "    \n",
    "    f, ax = plt.subplots(figsize=(15, 10))\n",
    "    cmap =sns.diverging_palette(128, 240,as_cmap=True)\n",
    "\n",
    "    sns.heatmap(attns, cmap='Wistia', linewidths=0.05, ax=ax,  xticklabels=test_data[index].src, yticklabels=x_labels)\n",
    "    ax.tick_params(axis='y', labelsize=15,labeltop=True)\n",
    "    ax.tick_params(axis='x', labelsize=15,labeltop=True, labelbottom=False)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), rotation=0)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:zyc]",
   "language": "python",
   "name": "conda-env-zyc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
